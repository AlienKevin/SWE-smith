#!/usr/bin/env python3
"""
Analyze Rust procedural bug generation (generation phase only, without validation).

This script analyzes the bugs generated by procedural modifications without
requiring validation results. It provides statistics on:
- Total bugs generated per profile
- Breakdown by modifier type
- Distribution of bugs across modifiers
- Per-profile and aggregate statistics

Usage:
    python scripts/analyze_rust_generation_only.py [--output OUTPUT_FILE]
"""

import argparse
import json
import os
from collections import defaultdict
from pathlib import Path
from typing import Any, Dict, List


RUST_PROFILES = [
    "dtolnay__anyhow.1d7ef1db",
    "marshallpierce__rust-base64.cac5ff84",
    "clap-rs__clap.3716f9f4",
    "hyperium__hyper.c88df788",
    "rust-itertools__itertools.041c733c",
    "serde-rs__json.cd55b5a0",
    "rust-lang__log.3aa1359e",
    "dtolnay__semver.37bcbe69",
    "tokio-rs__tokio.ab3ff69c",
    "uuid-rs__uuid.2fd9b614",
    "rust-lang__mdBook.37273ba8",
    "BurntSushi__rust-csv.da000888",
    "servo__html5ever.b93afc94",
    "BurntSushi__byteorder.5a82625f",
    "chronotope__chrono.d43108cb",
    "orium__rpds.3e7c8ae6",
    "rayon-rs__rayon.1fd20485",
    "BurntSushi__ripgrep.3b7fd442",
    "rust-lang__rust-clippy.f4f579f4",
]


def extract_modifier_name(filename: str) -> str:
    """Extract the modifier name from a bug filename."""
    if filename.startswith("bug__") and "__" in filename:
        parts = filename.split("__")
        if len(parts) >= 2:
            return parts[1]
    return "unknown"


def analyze_single_profile(repo_id: str) -> Dict[str, Any]:
    """Analyze bugs for a single repository profile."""
    bug_gen_dir = Path("logs/bug_gen") / repo_id

    result = {
        "repo_id": repo_id,
        "exists": False,
        "total_generated": 0,
        "by_modifier": defaultdict(lambda: {"generated": 0, "files": []}),
    }

    if not bug_gen_dir.exists():
        return result

    result["exists"] = True

    for root, _, files in os.walk(bug_gen_dir):
        for file in files:
            if file.startswith("bug__") and file.endswith(".diff"):
                result["total_generated"] += 1
                modifier_name = extract_modifier_name(file)
                result["by_modifier"][modifier_name]["generated"] += 1
                result["by_modifier"][modifier_name]["files"].append(
                    os.path.join(root, file)
                )

    result["by_modifier"] = dict(result["by_modifier"])

    return result


def aggregate_results(profile_results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Aggregate results from all profiles."""
    aggregated = {
        "total_profiles": len(profile_results),
        "profiles_with_data": sum(1 for r in profile_results if r["exists"]),
        "total_generated": sum(r["total_generated"] for r in profile_results),
        "by_modifier": defaultdict(
            lambda: {"generated": 0, "profiles_used": 0, "avg_per_profile": 0.0}
        ),
        "profile_results": profile_results,
    }

    for result in profile_results:
        if not result["exists"]:
            continue

        for modifier, data in result["by_modifier"].items():
            aggregated["by_modifier"][modifier]["generated"] += data["generated"]
            if data["generated"] > 0:
                aggregated["by_modifier"][modifier]["profiles_used"] += 1

    for modifier, data in aggregated["by_modifier"].items():
        if data["profiles_used"] > 0:
            data["avg_per_profile"] = data["generated"] / data["profiles_used"]

    aggregated["by_modifier"] = dict(aggregated["by_modifier"])

    return aggregated


def print_comprehensive_report(aggregated: Dict[str, Any]) -> None:
    """Print comprehensive report."""
    print("=" * 100)
    print("RUST PROCEDURAL BUG GENERATION ANALYSIS (Generation Phase Only)")
    print("=" * 100)
    print()

    print("OVERALL STATISTICS")
    print("-" * 100)
    print(f"Total Rust profiles:                {aggregated['total_profiles']}")
    print(
        f"Profiles with generated bugs:       {aggregated['profiles_with_data']}"
    )
    print(f"Total bugs generated:               {aggregated['total_generated']}")
    print(
        f"Average bugs per profile:           {aggregated['total_generated'] / max(aggregated['profiles_with_data'], 1):.1f}"
    )
    print()

    print("PER-MODIFIER EFFECTIVENESS")
    print("-" * 100)
    print(
        f"{'Modifier':<40} {'Generated':<12} {'Profiles Used':<15} {'Avg per Profile':<15}"
    )
    print("-" * 100)

    sorted_modifiers = sorted(
        aggregated["by_modifier"].items(),
        key=lambda x: x[1]["generated"],
        reverse=True,
    )

    for modifier, data in sorted_modifiers:
        print(
            f"{modifier:<40} {data['generated']:<12} {data['profiles_used']:<15} {data['avg_per_profile']:<15.1f}"
        )

    print()

    print("PER-PROFILE SUMMARY")
    print("-" * 100)
    print(f"{'Repository':<50} {'Generated':<12} {'Top Modifier':<30}")
    print("-" * 100)

    for result in aggregated["profile_results"]:
        if not result["exists"]:
            continue

        repo_name = result["repo_id"].replace("__", "/").rsplit(".", 1)[0]

        if result["by_modifier"]:
            top_modifier = max(
                result["by_modifier"].items(), key=lambda x: x[1]["generated"]
            )
            top_modifier_str = f"{top_modifier[0]} ({top_modifier[1]['generated']})"
        else:
            top_modifier_str = "N/A"

        print(
            f"{repo_name:<50} {result['total_generated']:<12} {top_modifier_str:<30}"
        )

    print()

    all_counts = [r["total_generated"] for r in aggregated["profile_results"] if r["exists"]]
    
    if all_counts:
        print("DISTRIBUTION STATISTICS")
        print("-" * 100)
        print(f"Min bugs per profile:               {min(all_counts)}")
        print(f"Max bugs per profile:               {max(all_counts)}")
        print(f"Median bugs per profile:            {sorted(all_counts)[len(all_counts) // 2]}")
        print(f"Std dev bugs per profile:           {(sum((x - sum(all_counts)/len(all_counts))**2 for x in all_counts) / len(all_counts))**0.5:.1f}")
        print()

    print("=" * 100)


def generate_markdown_report(aggregated: Dict[str, Any]) -> str:
    """Generate markdown report for GitHub issue."""
    md = []
    md.append("# Rust Procedural Bug Generation Analysis")
    md.append("")
    md.append("## Executive Summary")
    md.append("")
    md.append(
        f"- **Total Rust Profiles Tested**: {aggregated['profiles_with_data']}/{aggregated['total_profiles']}"
    )
    md.append(f"- **Total Bugs Generated**: {aggregated['total_generated']}")
    md.append(
        f"- **Average Bugs per Profile**: {aggregated['total_generated'] / max(aggregated['profiles_with_data'], 1):.1f}"
    )
    md.append("")

    md.append("## Key Findings")
    md.append("")

    if aggregated["by_modifier"]:
        most_prolific = max(
            aggregated["by_modifier"].items(), key=lambda x: x[1]["generated"]
        )
        md.append(
            f"- **Most Prolific Modifier**: `{most_prolific[0]}` generated {most_prolific[1]['generated']} bugs across {most_prolific[1]['profiles_used']} profiles"
        )

        most_consistent = max(
            aggregated["by_modifier"].items(), key=lambda x: x[1]["profiles_used"]
        )
        md.append(
            f"- **Most Consistent Modifier**: `{most_consistent[0]}` used in {most_consistent[1]['profiles_used']}/{aggregated['profiles_with_data']} profiles"
        )

    max_profile = max(
        (r for r in aggregated["profile_results"] if r["exists"]),
        key=lambda x: x["total_generated"],
    )
    md.append(
        f"- **Most Productive Profile**: {max_profile['repo_id'].replace('__', '/').rsplit('.', 1)[0]} with {max_profile['total_generated']} bugs"
    )

    md.append("")
    md.append("## Per-Modifier Effectiveness")
    md.append("")
    md.append("| Modifier | Generated | Profiles Used | Avg per Profile |")
    md.append("|----------|-----------|---------------|-----------------|")

    sorted_by_generated = sorted(
        aggregated["by_modifier"].items(),
        key=lambda x: x[1]["generated"],
        reverse=True,
    )

    for modifier, data in sorted_by_generated:
        md.append(
            f"| `{modifier}` | {data['generated']} | {data['profiles_used']} | {data['avg_per_profile']:.1f} |"
        )

    md.append("")
    md.append("## Per-Profile Results")
    md.append("")
    md.append("| Repository | Generated | Top Modifier |")
    md.append("|------------|-----------|--------------|")

    for result in aggregated["profile_results"]:
        if not result["exists"]:
            continue

        repo_name = result["repo_id"].replace("__", "/").rsplit(".", 1)[0]

        if result["by_modifier"]:
            top_modifier = max(
                result["by_modifier"].items(), key=lambda x: x[1]["generated"]
            )
            top_modifier_str = f"{top_modifier[0]} ({top_modifier[1]['generated']})"
        else:
            top_modifier_str = "N/A"

        md.append(f"| {repo_name} | {result['total_generated']} | {top_modifier_str} |")

    md.append("")
    md.append("## Methodology")
    md.append("")
    md.append("### Bug Generation")
    md.append(
        "Bugs were generated using 10 Rust procedural modifiers across three categories:"
    )
    md.append(
        "- **Control Flow** (2 modifiers): `func_pm_ctrl_invert_if`, `func_pm_ctrl_shuffle`"
    )
    md.append(
        "- **Operations** (5 modifiers): `func_pm_op_change`, `func_pm_op_swap`, `func_pm_flip_operators`, `func_pm_break_chains`, `func_pm_change_constants`"
    )
    md.append(
        "- **Remove** (3 modifiers): `func_pm_remove_assign`, `func_pm_remove_cond`, `func_pm_remove_loop`"
    )
    md.append("")
    md.append("### Process")
    md.append("1. Clone each Rust repository at the specified commit")
    md.append("2. Extract up to 100 code entities (functions) per repository")
    md.append("3. Apply each modifier to applicable entities")
    md.append("4. Generate diffs and metadata for each successful modification")
    md.append("")
    md.append("### Limitations")
    md.append(
        "- **No Validation**: This analysis only covers bug generation, not validation"
    )
    md.append(
        "- **No Docker**: Validation requires Docker images which were not available"
    )
    md.append(
        "- **Syntactic Only**: Generated bugs are syntactically valid but not tested for semantic correctness"
    )
    md.append("")
    md.append("## Commands Used")
    md.append("")
    md.append("```bash")
    md.append("# Generate bugs for all Rust profiles")
    md.append("uv run python scripts/test_rust_local.py --max-bugs 100")
    md.append("")
    md.append("# Analyze results")
    md.append("uv run python scripts/analyze_rust_generation_only.py")
    md.append("```")
    md.append("")
    md.append("## Next Steps")
    md.append("")
    md.append("To complete the full testing procedure from PR #3:")
    md.append("1. Build Docker images for all Rust profiles")
    md.append("2. Run validation: `python -m swesmith.harness.valid logs/bug_gen/<repo_id>_all_patches.json`")
    md.append("3. Analyze validation results: `python scripts/analyze_bugs.py <repo_id>`")
    md.append("4. Generate comprehensive report with validation data")
    md.append("")

    return "\n".join(md)


def main():
    parser = argparse.ArgumentParser(
        description="Analyze Rust procedural bug generation (generation phase only)"
    )
    parser.add_argument(
        "--output",
        "-o",
        type=str,
        default=None,
        help="Output file for detailed JSON report (default: logs/analysis/rust_generation_only.json)",
    )
    parser.add_argument(
        "--markdown",
        "-m",
        type=str,
        default=None,
        help="Output file for markdown report (default: logs/analysis/rust_generation_only.md)",
    )

    args = parser.parse_args()

    print("Analyzing all Rust profiles...")
    print()

    profile_results = []
    for repo_id in RUST_PROFILES:
        result = analyze_single_profile(repo_id)
        profile_results.append(result)
        if result["exists"]:
            print(f"✓ {repo_id}: {result['total_generated']} bugs generated")
        else:
            print(f"⊘ {repo_id}: No data found")

    print()

    aggregated = aggregate_results(profile_results)

    print_comprehensive_report(aggregated)

    if args.output is None:
        output_dir = Path("logs/analysis")
        output_dir.mkdir(parents=True, exist_ok=True)
        args.output = str(output_dir / "rust_generation_only.json")

    with open(args.output, "w") as f:
        json.dump(aggregated, f, indent=2)
    print(f"\nDetailed JSON report saved to: {args.output}")

    if args.markdown is None:
        output_dir = Path("logs/analysis")
        output_dir.mkdir(parents=True, exist_ok=True)
        args.markdown = str(output_dir / "rust_generation_only.md")

    markdown_content = generate_markdown_report(aggregated)
    with open(args.markdown, "w") as f:
        f.write(markdown_content)
    print(f"Markdown report saved to: {args.markdown}")


if __name__ == "__main__":
    main()
