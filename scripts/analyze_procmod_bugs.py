#!/usr/bin/env python3
"""
Analyze procedurally generated bugs and their validation results.

This script analyzes the bugs generated by procedural modifications and provides
detailed statistics about:
- Total bugs generated and validated
- Breakdown by modifier type
- Validation pass rates
- Test failure statistics
- Distribution of bugs across modifiers

Usage:
    python scripts/analyze_procmod_bugs.py [options]
    python scripts/analyze_procmod_bugs.py --repo <repo_id>  # Analyze single repo
    python scripts/analyze_procmod_bugs.py                   # Analyze all repos

Example:
    python scripts/analyze_procmod_bugs.py
    python scripts/analyze_procmod_bugs.py --repo dtolnay__anyhow.1d7ef1db
"""

import argparse
import json
import os
from collections import defaultdict
from pathlib import Path
from typing import Any, Dict

import matplotlib.pyplot as plt
import numpy as np

from swebench.harness.constants import FAIL_TO_PASS, LOG_REPORT, PASS_TO_PASS


def extract_modifier_name(instance_id: str) -> str:
    """Extract the modifier name from an instance ID.

    Example: Instagram__MonkeyType.70c3acf6.func_pm_remove_assign__abc123 -> func_pm_remove_assign
    """
    parts = instance_id.split(".")
    if len(parts) >= 3:
        last_part = parts[-1]
        if "__" in last_part:
            return last_part.split("__")[0]
    return "unknown"


def analyze_bugs(repo_id: str) -> Dict[str, Any]:
    """Analyze bugs for a given repository.

    Args:
        repo_id: Repository identifier (e.g., Instagram__MonkeyType.70c3acf6)

    Returns:
        Dictionary containing analysis results
    """
    bug_gen_dir = Path("logs/bug_gen") / repo_id
    validation_dir = Path("logs/run_validation") / repo_id

    if not bug_gen_dir.exists():
        raise FileNotFoundError(f"Bug generation directory not found: {bug_gen_dir}")

    generated_bugs = defaultdict(list)
    total_generated = 0

    for root, _, files in os.walk(bug_gen_dir):
        for file in files:
            if file.startswith("bug__") and file.endswith(".diff"):
                total_generated += 1
                modifier_name = file.split("bug__")[1].split("__")[0]
                instance_id = f"{repo_id}.{file.split('bug__')[1].replace('.diff', '')}"
                generated_bugs[modifier_name].append(instance_id)

    generated_bugs_len = sum(len(v) for v in generated_bugs.values())
    assert generated_bugs_len == total_generated

    validated_bugs = defaultdict(
        lambda: {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "f2p_counts": [],
            "p2p_counts": [],
            "instances": [],
        }
    )

    timeout_bugs = defaultdict(list)
    total_timeouts = 0
    total_validated = 0
    total_passed = 0
    total_failed = 0

    if validation_dir.exists():
        for instance_dir in os.listdir(validation_dir):
            # Skip reference tests
            if instance_dir.endswith(".ref"):
                print(f"Skipping {instance_dir} because it is a reference test")
                continue

            instance_path = validation_dir / instance_dir
            report_path = instance_path / LOG_REPORT

            if report_path.exists():
                with open(report_path, "r") as f:
                    report = json.load(f)

                modifier_name = extract_modifier_name(instance_dir)

                # Exclude if report timed_out is true
                if report.get("timed_out", False):
                    print(f"Timeout bug from timed_out == True: {instance_dir}")
                    timeout_bugs[modifier_name].append(instance_dir)
                    continue

                total_validated += 1

                f2p_count = len(report.get(FAIL_TO_PASS, []))
                p2p_count = len(report.get(PASS_TO_PASS, []))

                validated_bugs[modifier_name]["total"] += 1
                validated_bugs[modifier_name]["f2p_counts"].append(f2p_count)
                validated_bugs[modifier_name]["p2p_counts"].append(p2p_count)
                validated_bugs[modifier_name]["instances"].append(
                    {"instance_id": instance_dir, "f2p": f2p_count, "p2p": p2p_count}
                )

                if f2p_count > 0:
                    validated_bugs[modifier_name]["passed"] += 1
                    total_passed += 1
                else:
                    validated_bugs[modifier_name]["failed"] += 1
                    total_failed += 1
            else:
                print(f"Timeout bug from missing report: {instance_dir}")
                timeout_bugs[modifier_name].append(instance_dir)

    total_timeouts = total_generated - total_validated
    # Add generated bugs that are missing from the validated folder to timeout_bugs
    for modifier_name, bug_list in generated_bugs.items():
        for bug_id in bug_list:
            instance_path = validation_dir / bug_id
            # If the bug was generated but not validated (not in validation folder)
            if not instance_path.exists():
                print(f"Timeout bug from missing validation folder: {bug_id}")
                timeout_bugs[modifier_name].append(bug_id)

    return {
        "repo_id": repo_id,
        "total_generated": total_generated,
        "total_validated": total_validated,
        "total_passed": total_passed,
        "total_failed": total_failed,
        "total_timeouts": total_timeouts,
        "generated_by_modifier": {k: len(v) for k, v in generated_bugs.items()},
        "validated_by_modifier": dict(validated_bugs),
        "timeout_by_modifier": {k: len(v) for k, v in timeout_bugs.items()},
    }


def print_statistics(analysis: Dict[str, Any]) -> None:
    """Print detailed statistics from the analysis."""

    print("=" * 80)
    print(f"Bug Generation and Validation Analysis for {analysis['repo_id']}")
    print("=" * 80)
    print()

    print("OVERALL STATISTICS")
    print("-" * 80)
    print(f"Total bugs generated:           {analysis['total_generated']}")
    print(f"Total bugs validated:           {analysis['total_validated']}")
    print(
        f"Bugs that passed validation:    {analysis['total_passed']} ({analysis['total_passed'] / max(analysis['total_validated'], 1) * 100:.1f}%)"
    )
    print(
        f"Bugs that failed validation:    {analysis['total_failed']} ({analysis['total_failed'] / max(analysis['total_validated'], 1) * 100:.1f}%)"
    )
    print()

    print("PER-MODIFIER STATISTICS")
    print("-" * 80)
    print(
        f"{'Modifier':<35} {'Generated':<12} {'Validated':<12} {'Passed':<12} {'Pass Rate':<12}"
    )
    print("-" * 80)

    sorted_modifiers = sorted(
        analysis["generated_by_modifier"].items(), key=lambda x: x[1], reverse=True
    )

    for modifier, generated_count in sorted_modifiers:
        validated_data = analysis["validated_by_modifier"].get(modifier, {})
        validated_count = validated_data.get("total", 0)
        passed_count = validated_data.get("passed", 0)
        pass_rate = (passed_count / max(validated_count, 1)) * 100

        print(
            f"{modifier:<35} {generated_count:<12} {validated_count:<12} {passed_count:<12} {pass_rate:>10.1f}%"
        )

    print()

    print("TEST FAILURE STATISTICS")
    print("-" * 80)
    print(
        f"{'Modifier':<35} {'Avg F2P':<12} {'Min F2P':<12} {'Max F2P':<12} {'Avg P2P':<12}"
    )
    print("-" * 80)

    for modifier, generated_count in sorted_modifiers:
        validated_data = analysis["validated_by_modifier"].get(modifier, {})
        f2p_counts = validated_data.get("f2p_counts", [])
        p2p_counts = validated_data.get("p2p_counts", [])

        if f2p_counts:
            avg_f2p = sum(f2p_counts) / len(f2p_counts)
            min_f2p = min(f2p_counts)
            max_f2p = max(f2p_counts)
            avg_p2p = sum(p2p_counts) / len(p2p_counts)

            print(
                f"{modifier:<35} {avg_f2p:<12.2f} {min_f2p:<12} {max_f2p:<12} {avg_p2p:<12.2f}"
            )

    print()

    print("DISTRIBUTION SUMMARY")
    print("-" * 80)

    all_f2p = []
    all_p2p = []
    for validated_data in analysis["validated_by_modifier"].values():
        all_f2p.extend(validated_data.get("f2p_counts", []))
        all_p2p.extend(validated_data.get("p2p_counts", []))

    if all_f2p:
        print(
            f"Average tests broken per bug (F2P):     {sum(all_f2p) / len(all_f2p):.2f}"
        )
        print(
            f"Median tests broken per bug (F2P):      {sorted(all_f2p)[len(all_f2p) // 2]}"
        )
        print(f"Min tests broken per bug (F2P):         {min(all_f2p)}")
        print(f"Max tests broken per bug (F2P):         {max(all_f2p)}")
        print()
        print(
            f"Average tests maintained per bug (P2P): {sum(all_p2p) / len(all_p2p):.2f}"
        )
        print(
            f"Median tests maintained per bug (P2P):  {sorted(all_p2p)[len(all_p2p) // 2]}"
        )

    print()
    print("=" * 80)


def save_report(analysis: Dict[str, Any], output_file: str) -> None:
    """Save the analysis report to a JSON file."""
    with open(output_file, "w") as f:
        json.dump(analysis, f, indent=2)
    print(f"Detailed report saved to: {output_file}")


def plot_bug_distribution(
    analysis: Dict[str, Any],
    output_path: str,
    show_generated_bugs: bool = False,
    show_timeout_bugs: bool = False,
) -> None:
    """Plot bar chart of bug distribution by modifier type.

    Args:
        analysis: Analysis results dictionary
        output_path: Path to save the plot
        show_generated_bugs: Whether to show generated bugs bar
        show_timeout_bugs: Whether to show timeout bugs bar stacked on validated
    """
    # Extract data
    generated_by_modifier = analysis.get("generated_by_modifier", {})
    validated_by_modifier = analysis.get("validated_by_modifier", {})
    timeout_by_modifier = analysis.get("timeout_by_modifier", {})

    # If it's aggregate data, handle differently
    if "aggregate_statistics" in analysis:
        modifier_data = analysis["aggregate_statistics"]["by_modifier"]
        generated_by_modifier = {k: v["generated"] for k, v in modifier_data.items()}
        validated_by_modifier = {
            k: {"total": v["validated"], "passed": v["passed"]}
            for k, v in modifier_data.items()
        }
        timeout_by_modifier = {k: v.get("timeout", 0) for k, v in modifier_data.items()}

    if not generated_by_modifier:
        print("No data to plot")
        return

    # Sort modifiers by generated count (descending)
    sorted_modifiers = sorted(
        generated_by_modifier.items(), key=lambda x: x[1], reverse=True
    )

    modifier_keys = [m[0] for m in sorted_modifiers]
    modifiers_display = [m[0].replace("func_pm_", "") for m in sorted_modifiers]
    generated_counts = [m[1] for m in sorted_modifiers]

    # Get validated, passed, and timeout counts for each modifier
    validated_counts = []
    passed_counts = []
    timeout_counts = []
    for modifier_key in modifier_keys:
        if modifier_key in validated_by_modifier:
            if isinstance(validated_by_modifier[modifier_key], dict):
                validated_counts.append(
                    validated_by_modifier[modifier_key].get("total", 0)
                )
                passed_counts.append(
                    validated_by_modifier[modifier_key].get("passed", 0)
                )
            else:
                validated_counts.append(validated_by_modifier[modifier_key])
                passed_counts.append(0)
        else:
            validated_counts.append(0)
            passed_counts.append(0)

        # Get timeout count for this modifier
        timeout_counts.append(timeout_by_modifier.get(modifier_key, 0))

    # Filter out modifiers with zero passed bugs
    filtered_data = [
        (mod, gen, val, pas, tim)
        for mod, gen, val, pas, tim in zip(
            modifiers_display,
            generated_counts,
            validated_counts,
            passed_counts,
            timeout_counts,
        )
        if pas > 0
    ]

    if not filtered_data:
        print("No modifiers with passed bugs to plot")
        return

    # Unpack filtered data
    (
        modifiers_display,
        generated_counts,
        validated_counts,
        passed_counts,
        timeout_counts,
    ) = zip(*filtered_data)

    # Create figure and axis
    fig, ax = plt.subplots(figsize=(14, 8.8))

    # Set positions for bars
    x = np.arange(len(modifiers_display))
    width = 0.6

    # Create overlaid bars (drawn from back to front)
    if show_generated_bugs:
        # Back: Generated (lightgray - 10% darker than whitesmoke)
        bars0 = ax.bar(
            x,
            generated_counts,
            width,
            label="Generated",
            color="lightgray",
            edgecolor="none",
            zorder=1,
        )
        # Middle: Validated (gray - 10% darker than silver)
        bars1 = ax.bar(
            x,
            validated_counts,
            width,
            label="Validated",
            color="gray",
            edgecolor="none",
            zorder=2,
        )
        # Front: Passed (black) - overlay on validated
        bars2 = ax.bar(
            x,
            passed_counts,
            width,
            label="Passed",
            color="black",
            edgecolor="none",
            zorder=3,
        )
        # Timeout bars stacked on top of validated (dotted pattern)
        if show_timeout_bugs:
            bars3 = ax.bar(
                x,
                timeout_counts,
                width,
                bottom=validated_counts,
                label="Timeout",
                color="gray",
                edgecolor="black",
                linewidth=0,
                hatch="...",
                zorder=4,
            )
    else:
        # Back: Validated (light grey)
        bars1 = ax.bar(
            x,
            validated_counts,
            width,
            label="Validated",
            color="lightgrey",
            edgecolor="none",
            zorder=1,
        )
        # Front: Passed (black) - overlay on validated
        bars2 = ax.bar(
            x,
            passed_counts,
            width,
            label="Passed",
            color="black",
            edgecolor="none",
            zorder=2,
        )
        # Timeout bars stacked on top of validated (dotted pattern)
        if show_timeout_bugs:
            bars3 = ax.bar(
                x,
                timeout_counts,
                width,
                bottom=validated_counts,
                label="Timeout",
                color="lightgrey",
                edgecolor="black",
                linewidth=0,
                hatch="...",
                zorder=3,
            )

    # Customize plot
    ax.set_xlabel("Modifier Type", fontsize=22, fontweight="bold")
    ax.set_ylabel("Number of Bugs", fontsize=22, fontweight="bold")
    ax.set_title(
        "Bug Distribution by Modifier Type", fontsize=24, fontweight="bold", pad=20
    )
    ax.set_xticks(x)
    ax.set_xticklabels(modifiers_display, rotation=45, ha="right", fontsize=20)
    ax.tick_params(axis="y", labelsize=20)
    ax.legend(fontsize=20, loc="upper right")
    ax.grid(axis="y", alpha=0.3, linestyle="--")

    # Add value labels on bars
    if show_generated_bugs:
        for i, (gen, val, pas, tim) in enumerate(
            zip(generated_counts, validated_counts, passed_counts, timeout_counts)
        ):
            # Label for generated (at the top of generated bar)
            ax.text(
                x[i],
                gen,
                f"{int(gen)}",
                ha="center",
                va="bottom",
                fontsize=16,
                fontweight="bold",
                color="dimgrey",
            )
            # Label for validated (at the top of validated bar)
            if not show_timeout_bugs:
                ax.text(
                    x[i],
                    val,
                    f"{int(val)}",
                    ha="center",
                    va="bottom",
                    fontsize=16,
                    fontweight="bold",
                    color="dimgrey",
                )
            # Label for passed (at the top of passed bar)
            ax.text(
                x[i],
                pas,
                f"{int(pas)}",
                ha="center",
                va="bottom",
                fontsize=16,
                fontweight="bold",
                color="white",
            )
            # Label for timeout (at the top of timeout bar)
            if show_timeout_bugs and tim > 0:
                ax.text(
                    x[i],
                    val + tim,
                    f"{int(gen)}",
                    ha="center",
                    va="bottom",
                    fontsize=16,
                    fontweight="bold",
                    color="dimgrey",
                )
    else:
        for i, (gen, val, pas, tim) in enumerate(
            zip(generated_counts, validated_counts, passed_counts, timeout_counts)
        ):
            # Label for validated (at the top of validated bar)
            if not show_timeout_bugs:
                ax.text(
                    x[i],
                    val,
                    f"{int(val)}",
                    ha="center",
                    va="bottom",
                    fontsize=16,
                    fontweight="bold",
                    color="dimgrey",
                )
            # Label for passed (at the top of passed bar)
            ax.text(
                x[i],
                pas,
                f"{int(pas)}",
                ha="center",
                va="bottom",
                fontsize=16,
                fontweight="bold",
                color="black",
            )
            # Label for timeout (at the top of timeout bar)
            if show_timeout_bugs and tim > 0:
                ax.text(
                    x[i],
                    val + tim,
                    f"{int(gen)}",
                    ha="center",
                    va="bottom",
                    fontsize=16,
                    fontweight="bold",
                    color="dimgrey",
                )

    # Tight layout to prevent label cutoff
    plt.tight_layout()

    # Ensure output directory exists
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)

    # Save plot
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    plt.close()

    print(f"Bug distribution plot saved to: {output_path}")


def plot_per_repo_distribution(
    all_analyses: list[Dict[str, Any]], output_path: str, show_repo_owner: bool = False
) -> None:
    """Plot per-repo breakdown of validated, passed, and timeout bugs.

    Args:
        all_analyses: List of analysis results for each repo
        output_path: Path to save the plot
        show_repo_owner: Whether to show repo owner in labels
    """
    if not all_analyses:
        print("No data to plot")
        return

    # Extract data per repo
    repos = [a["repo_id"] for a in all_analyses]
    validated = [a["total_validated"] for a in all_analyses]
    passed = [a["total_passed"] for a in all_analyses]
    timeout = [a.get("total_timeouts", 0) for a in all_analyses]

    # Truncate commit_id from repo names (remove part after last dot)
    repos_display = [r.rsplit(".", 1)[0] for r in repos]

    # Replace __ with / and optionally hide owner
    if show_repo_owner:
        repos_display = [r.replace("__", "/") for r in repos_display]
    else:
        # Hide owner (everything before and including __)
        repos_display = [
            r.split("__", 1)[-1] if "__" in r else r for r in repos_display
        ]

    # Create figure
    fig, ax = plt.subplots(figsize=(16, 10))

    x = np.arange(len(repos))
    width = 0.25

    # Create grouped bars
    ax.bar(x - width, validated, width, label="Validated", color="lightgrey")
    ax.bar(x, passed, width, label="Passed", color="black")
    ax.bar(x + width, timeout, width, label="Timeout", color="lightgrey", hatch="...")

    # Customize plot
    ax.set_xlabel("Repository", fontsize=22, fontweight="bold")
    ax.set_ylabel("Number of Bugs", fontsize=22, fontweight="bold")
    ax.set_title(
        "Per-Repository Bug Distribution", fontsize=24, fontweight="bold", pad=20
    )
    ax.set_xticks(x)
    ax.set_xticklabels(repos_display, rotation=45, ha="right", fontsize=14)
    ax.tick_params(axis="y", labelsize=20)
    ax.legend(fontsize=20, loc="upper right")
    ax.grid(axis="y", alpha=0.3, linestyle="--")

    plt.tight_layout()

    # Ensure output directory exists
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)

    # Save plot
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    plt.close()

    print(f"Per-repo distribution plot saved to: {output_path}")


def discover_repos() -> list[str]:
    """Discover all repos under logs/run_validation.

    Returns:
        List of repo IDs found in the validation directory
    """
    validation_base = Path("logs/run_validation")
    if not validation_base.exists():
        return []

    repos = []
    for item in validation_base.iterdir():
        if item.is_dir():
            repos.append(item.name)

    return sorted(repos)


def print_aggregate_statistics(all_analyses: list[Dict[str, Any]]) -> None:
    """Print aggregate statistics across all repos."""

    total_repos = len(all_analyses)
    total_generated = sum(a["total_generated"] for a in all_analyses)
    total_validated = sum(a["total_validated"] for a in all_analyses)
    total_passed = sum(a["total_passed"] for a in all_analyses)
    total_failed = sum(a["total_failed"] for a in all_analyses)
    total_timeouts = sum(a.get("total_timeouts", 0) for a in all_analyses)

    # Aggregate by modifier across all repos
    modifier_stats = defaultdict(
        lambda: {
            "generated": 0,
            "validated": 0,
            "passed": 0,
            "failed": 0,
            "timeout": 0,
            "f2p_counts": [],
            "p2p_counts": [],
        }
    )

    for analysis in all_analyses:
        for modifier, count in analysis["generated_by_modifier"].items():
            modifier_stats[modifier]["generated"] += count

        for modifier, data in analysis["validated_by_modifier"].items():
            modifier_stats[modifier]["validated"] += data["total"]
            modifier_stats[modifier]["passed"] += data["passed"]
            modifier_stats[modifier]["failed"] += data["failed"]
            modifier_stats[modifier]["f2p_counts"].extend(data["f2p_counts"])
            modifier_stats[modifier]["p2p_counts"].extend(data["p2p_counts"])

        for modifier, count in analysis.get("timeout_by_modifier", {}).items():
            modifier_stats[modifier]["timeout"] += count

    print("\n")
    print("=" * 80)
    print("AGGREGATE STATISTICS ACROSS ALL REPOS")
    print("=" * 80)
    print()

    print("OVERALL STATISTICS")
    print("-" * 80)
    print(f"Total repositories analyzed:    {total_repos}")
    print(f"Total bugs generated:           {total_generated}")
    print(f"Total bugs validated:           {total_validated}")
    if total_validated > 0:
        print(
            f"Bugs that passed validation:    {total_passed} ({total_passed / total_validated * 100:.1f}%)"
        )
        print(
            f"Bugs that failed validation:    {total_failed} ({total_failed / total_validated * 100:.1f}%)"
        )
    print()

    print("PER-MODIFIER STATISTICS (AGGREGATED)")
    print("-" * 80)
    print(
        f"{'Modifier':<35} {'Generated':<12} {'Validated':<12} {'Passed':<12} {'Pass Rate':<12}"
    )
    print("-" * 80)

    sorted_modifiers = sorted(
        modifier_stats.items(), key=lambda x: x[1]["generated"], reverse=True
    )

    for modifier, stats in sorted_modifiers:
        validated_count = stats["validated"]
        passed_count = stats["passed"]
        pass_rate = (passed_count / max(validated_count, 1)) * 100

        print(
            f"{modifier:<35} {stats['generated']:<12} {validated_count:<12} {passed_count:<12} {pass_rate:>10.1f}%"
        )

    print()

    print("TEST FAILURE STATISTICS (AGGREGATED)")
    print("-" * 80)
    print(
        f"{'Modifier':<35} {'Avg F2P':<12} {'Min F2P':<12} {'Max F2P':<12} {'Avg P2P':<12}"
    )
    print("-" * 80)

    for modifier, stats in sorted_modifiers:
        f2p_counts = stats["f2p_counts"]
        p2p_counts = stats["p2p_counts"]

        if f2p_counts:
            avg_f2p = sum(f2p_counts) / len(f2p_counts)
            min_f2p = min(f2p_counts)
            max_f2p = max(f2p_counts)
            avg_p2p = sum(p2p_counts) / len(p2p_counts)

            print(
                f"{modifier:<35} {avg_f2p:<12.2f} {min_f2p:<12} {max_f2p:<12} {avg_p2p:<12.2f}"
            )

    print()
    print("=" * 80)


def main():
    parser = argparse.ArgumentParser(
        description="Analyze procedurally generated bugs and validation results"
    )
    parser.add_argument(
        "--repo",
        "-r",
        type=str,
        default=None,
        help="Repository identifier (e.g., Instagram__MonkeyType.70c3acf6). If not provided, analyzes all repos.",
    )
    parser.add_argument(
        "--output",
        "-o",
        type=str,
        default=None,
        help="Output file for detailed JSON report (default: logs/analysis/<repo_id>_analysis.json or logs/analysis/aggregate_analysis.json)",
    )
    parser.add_argument(
        "--show-generated-bugs",
        action="store_true",
        default=False,
        help="Show generated bugs as another bar behind validated and passed. If enabled, validated bar shows in grey and generated in light grey.",
    )
    parser.add_argument(
        "--show-timeout-bugs",
        action="store_true",
        default=False,
        help="Show timeout bugs as a dotted bar stacked on top of validated bugs.",
    )
    parser.add_argument(
        "--show-repo-owner",
        action="store_true",
        default=False,
        help="Show repository owner in per-repo plot labels.",
    )

    args = parser.parse_args()

    if args.repo:
        # Analyze single repo
        analysis = analyze_bugs(args.repo)
        print_statistics(analysis)

        if args.output is None:
            output_dir = Path("logs/analysis")
            output_dir.mkdir(parents=True, exist_ok=True)
            args.output = str(output_dir / f"{args.repo}_analysis.json")

        save_report(analysis, args.output)

        # Plot bug distribution
        plot_output = Path("logs/analysis") / "bug_distribution.png"
        plot_bug_distribution(
            analysis, str(plot_output), args.show_generated_bugs, args.show_timeout_bugs
        )
    else:
        # Analyze all repos
        repos = discover_repos()

        if not repos:
            print("No repositories found in logs/run_validation/")
            return

        print(f"Found {len(repos)} repositories to analyze")
        print()

        all_analyses = []

        for repo in repos:
            try:
                analysis = analyze_bugs(repo)
                all_analyses.append(analysis)
                print_statistics(analysis)
                print()
            except FileNotFoundError as e:
                print(f"Skipping {repo}: {e}")
                print()

        if all_analyses:
            print_aggregate_statistics(all_analyses)

            # Save aggregate report
            if args.output is None:
                output_dir = Path("logs/analysis")
                output_dir.mkdir(parents=True, exist_ok=True)
                args.output = str(output_dir / "aggregate_analysis.json")

            # Calculate aggregate statistics for JSON
            total_generated = sum(a["total_generated"] for a in all_analyses)
            total_validated = sum(a["total_validated"] for a in all_analyses)
            total_passed = sum(a["total_passed"] for a in all_analyses)
            total_failed = sum(a["total_failed"] for a in all_analyses)
            total_timeouts = sum(a.get("total_timeouts", 0) for a in all_analyses)

            modifier_stats = defaultdict(
                lambda: {
                    "generated": 0,
                    "validated": 0,
                    "passed": 0,
                    "failed": 0,
                    "timeout": 0,
                    "f2p_counts": [],
                    "p2p_counts": [],
                }
            )

            for analysis in all_analyses:
                for modifier, count in analysis["generated_by_modifier"].items():
                    modifier_stats[modifier]["generated"] += count

                for modifier, data in analysis["validated_by_modifier"].items():
                    modifier_stats[modifier]["validated"] += data["total"]
                    modifier_stats[modifier]["passed"] += data["passed"]
                    modifier_stats[modifier]["failed"] += data["failed"]
                    modifier_stats[modifier]["f2p_counts"].extend(data["f2p_counts"])
                    modifier_stats[modifier]["p2p_counts"].extend(data["p2p_counts"])

                for modifier, count in analysis.get("timeout_by_modifier", {}).items():
                    modifier_stats[modifier]["timeout"] += count

            # Calculate summary statistics for each modifier
            modifier_summaries = {}
            for modifier, stats in modifier_stats.items():
                summary = {
                    "generated": stats["generated"],
                    "validated": stats["validated"],
                    "passed": stats["passed"],
                    "failed": stats["failed"],
                    "timeout": stats["timeout"],
                    "pass_rate": (stats["passed"] / max(stats["validated"], 1)) * 100,
                }

                if stats["f2p_counts"]:
                    summary["f2p_avg"] = sum(stats["f2p_counts"]) / len(
                        stats["f2p_counts"]
                    )
                    summary["f2p_min"] = min(stats["f2p_counts"])
                    summary["f2p_max"] = max(stats["f2p_counts"])
                    summary["p2p_avg"] = sum(stats["p2p_counts"]) / len(
                        stats["p2p_counts"]
                    )

                modifier_summaries[modifier] = summary

            aggregate_data = {
                "total_repos": len(all_analyses),
                "repos": [a["repo_id"] for a in all_analyses],
                "aggregate_statistics": {
                    "total_generated": total_generated,
                    "total_validated": total_validated,
                    "total_passed": total_passed,
                    "total_failed": total_failed,
                    "total_timeouts": total_timeouts,
                    "pass_rate": (total_passed / max(total_validated, 1)) * 100,
                    "by_modifier": modifier_summaries,
                },
                "individual_analyses": all_analyses,
            }
            save_report(aggregate_data, args.output)

            # Plot aggregate bug distribution
            plot_output = Path("logs/analysis") / "bug_distribution.png"
            plot_bug_distribution(
                aggregate_data,
                str(plot_output),
                args.show_generated_bugs,
                args.show_timeout_bugs,
            )

            # Plot per-repo distribution
            per_repo_output = Path("logs/analysis") / "per_repo_bug_distribution.png"
            plot_per_repo_distribution(
                all_analyses, str(per_repo_output), args.show_repo_owner
            )


if __name__ == "__main__":
    main()
