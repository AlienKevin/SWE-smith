#!/usr/bin/env python3
"""
Analyze procedurally generated bugs and their validation results.

This script analyzes the bugs generated by procedural modifications and provides
detailed statistics about:
- Total bugs generated and validated
- Breakdown by modifier type
- Validation pass rates
- Test failure statistics
- Distribution of bugs across modifiers

Usage:
    python scripts/analyze_procmod_bugs.py [options]
    python scripts/analyze_procmod_bugs.py --repo <repo_id>  # Analyze single repo
    python scripts/analyze_procmod_bugs.py                   # Analyze all repos

Example:
    python scripts/analyze_procmod_bugs.py
    python scripts/analyze_procmod_bugs.py --repo dtolnay__anyhow.1d7ef1db
"""

import argparse
import json
import os
import re
import subprocess
import time
from collections import defaultdict
from pathlib import Path
from typing import Any, Dict

import matplotlib.pyplot as plt
import numpy as np

from swebench.harness.constants import FAIL_TO_PASS, LOG_REPORT, PASS_TO_PASS


def extract_modifier_name(instance_id: str) -> str:
    """Extract the modifier name from an instance ID.

    Example: Instagram__MonkeyType.70c3acf6.func_pm_remove_assign__abc123 -> func_pm_remove_assign
    """
    parts = instance_id.split(".")
    if len(parts) >= 3:
        last_part = parts[-1]
        if "__" in last_part:
            return last_part.split("__")[0]
    return "unknown"


def extract_test_count(repo_id: str) -> int:
    """Extract total number of unit tests from test_output.txt.

    Looks for lines containing 'test result: ok. X passed' and sums up all X values.

    Args:
        repo_id: Repository identifier (e.g., Instagram__MonkeyType.70c3acf6)

    Returns:
        Total number of tests, or 0 if test_output.txt not found
    """
    test_output_path = (
        Path("logs/run_validation") / repo_id / f"{repo_id}.ref" / "test_output.txt"
    )

    if not test_output_path.exists():
        return 0

    total_tests = 0
    pattern = re.compile(r"test result: ok\. (\d+) passed")

    try:
        with open(test_output_path, "r") as f:
            for line in f:
                match = pattern.search(line)
                if match:
                    total_tests += int(match.group(1))
    except Exception as e:
        print(f"Warning: Could not read test output for {repo_id}: {e}")
        return 0

    return total_tests


def analyze_bugs(repo_id: str) -> Dict[str, Any]:
    """Analyze bugs for a given repository.

    Args:
        repo_id: Repository identifier (e.g., Instagram__MonkeyType.70c3acf6)

    Returns:
        Dictionary containing analysis results
    """
    bug_gen_dir = Path("logs/bug_gen") / repo_id
    validation_dir = Path("logs/run_validation") / repo_id

    if not bug_gen_dir.exists():
        raise FileNotFoundError(f"Bug generation directory not found: {bug_gen_dir}")

    generated_bugs = defaultdict(list)
    total_generated = 0

    for root, _, files in os.walk(bug_gen_dir):
        for file in files:
            if file.startswith("bug__") and file.endswith(".diff"):
                total_generated += 1
                modifier_name = file.split("bug__")[1].split("__")[0]
                instance_id = f"{repo_id}.{file.split('bug__')[1].replace('.diff', '')}"
                generated_bugs[modifier_name].append(instance_id)

    generated_bugs_len = sum(len(v) for v in generated_bugs.values())
    assert generated_bugs_len == total_generated

    validated_bugs = defaultdict(
        lambda: {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "f2p_counts": [],
            "p2p_counts": [],
            "instances": [],
        }
    )

    timeout_bugs = defaultdict(list)
    total_timeouts = 0
    total_validated = 0
    total_passed = 0
    total_failed = 0

    if validation_dir.exists():
        for instance_dir in os.listdir(validation_dir):
            # Skip reference tests
            if instance_dir.endswith(".ref"):
                print(f"Skipping {instance_dir} because it is a reference test")
                continue

            instance_path = validation_dir / instance_dir
            report_path = instance_path / LOG_REPORT

            if report_path.exists():
                with open(report_path, "r") as f:
                    report = json.load(f)

                modifier_name = extract_modifier_name(instance_dir)

                # Exclude if report timed_out is true
                if report.get("timed_out", False):
                    print(f"Timeout bug from timed_out == True: {instance_dir}")
                    timeout_bugs[modifier_name].append(instance_dir)
                    continue

                total_validated += 1

                f2p_count = len(report.get(FAIL_TO_PASS, []))
                p2p_count = len(report.get(PASS_TO_PASS, []))

                validated_bugs[modifier_name]["total"] += 1
                validated_bugs[modifier_name]["f2p_counts"].append(f2p_count)
                validated_bugs[modifier_name]["p2p_counts"].append(p2p_count)
                validated_bugs[modifier_name]["instances"].append(
                    {"instance_id": instance_dir, "f2p": f2p_count, "p2p": p2p_count}
                )

                if f2p_count > 0:
                    validated_bugs[modifier_name]["passed"] += 1
                    total_passed += 1
                else:
                    validated_bugs[modifier_name]["failed"] += 1
                    total_failed += 1
            else:
                print(f"Timeout bug from missing report: {instance_dir}")
                timeout_bugs[modifier_name].append(instance_dir)

    total_timeouts = total_generated - total_validated
    # Add generated bugs that are missing from the validated folder to timeout_bugs
    for modifier_name, bug_list in generated_bugs.items():
        for bug_id in bug_list:
            instance_path = validation_dir / bug_id
            # If the bug was generated but not validated (not in validation folder)
            if not instance_path.exists():
                print(f"Timeout bug from missing validation folder: {bug_id}")
                timeout_bugs[modifier_name].append(bug_id)

    # Extract test count
    test_count = extract_test_count(repo_id)

    return {
        "repo_id": repo_id,
        "total_generated": total_generated,
        "total_validated": total_validated,
        "total_passed": total_passed,
        "total_failed": total_failed,
        "total_timeouts": total_timeouts,
        "test_count": test_count,
        "generated_by_modifier": {k: len(v) for k, v in generated_bugs.items()},
        "validated_by_modifier": dict(validated_bugs),
        "timeout_by_modifier": {k: len(v) for k, v in timeout_bugs.items()},
    }


def print_statistics(analysis: Dict[str, Any]) -> None:
    """Print detailed statistics from the analysis."""

    print("=" * 80)
    print(f"Bug Generation and Validation Analysis for {analysis['repo_id']}")
    print("=" * 80)
    print()

    print("OVERALL STATISTICS")
    print("-" * 80)
    print(f"Total bugs generated:           {analysis['total_generated']}")
    print(f"Total bugs validated:           {analysis['total_validated']}")
    print(
        f"Bugs that passed validation:    {analysis['total_passed']} ({analysis['total_passed'] / max(analysis['total_validated'], 1) * 100:.1f}%)"
    )
    print(
        f"Bugs that failed validation:    {analysis['total_failed']} ({analysis['total_failed'] / max(analysis['total_validated'], 1) * 100:.1f}%)"
    )
    print()

    print("PER-MODIFIER STATISTICS")
    print("-" * 80)
    print(
        f"{'Modifier':<35} {'Generated':<12} {'Validated':<12} {'Passed':<12} {'Pass Rate':<12}"
    )
    print("-" * 80)

    sorted_modifiers = sorted(
        analysis["generated_by_modifier"].items(), key=lambda x: x[1], reverse=True
    )

    for modifier, generated_count in sorted_modifiers:
        validated_data = analysis["validated_by_modifier"].get(modifier, {})
        validated_count = validated_data.get("total", 0)
        passed_count = validated_data.get("passed", 0)
        pass_rate = (passed_count / max(validated_count, 1)) * 100

        print(
            f"{modifier:<35} {generated_count:<12} {validated_count:<12} {passed_count:<12} {pass_rate:>10.1f}%"
        )

    print()

    print("TEST FAILURE STATISTICS")
    print("-" * 80)
    print(
        f"{'Modifier':<35} {'Avg F2P':<12} {'Min F2P':<12} {'Max F2P':<12} {'Avg P2P':<12}"
    )
    print("-" * 80)

    for modifier, generated_count in sorted_modifiers:
        validated_data = analysis["validated_by_modifier"].get(modifier, {})
        f2p_counts = validated_data.get("f2p_counts", [])
        p2p_counts = validated_data.get("p2p_counts", [])

        if f2p_counts:
            avg_f2p = sum(f2p_counts) / len(f2p_counts)
            min_f2p = min(f2p_counts)
            max_f2p = max(f2p_counts)
            avg_p2p = sum(p2p_counts) / len(p2p_counts)

            print(
                f"{modifier:<35} {avg_f2p:<12.2f} {min_f2p:<12} {max_f2p:<12} {avg_p2p:<12.2f}"
            )

    print()

    print("DISTRIBUTION SUMMARY")
    print("-" * 80)

    all_f2p = []
    all_p2p = []
    for validated_data in analysis["validated_by_modifier"].values():
        all_f2p.extend(validated_data.get("f2p_counts", []))
        all_p2p.extend(validated_data.get("p2p_counts", []))

    if all_f2p:
        print(
            f"Average tests broken per bug (F2P):     {sum(all_f2p) / len(all_f2p):.2f}"
        )
        print(
            f"Median tests broken per bug (F2P):      {sorted(all_f2p)[len(all_f2p) // 2]}"
        )
        print(f"Min tests broken per bug (F2P):         {min(all_f2p)}")
        print(f"Max tests broken per bug (F2P):         {max(all_f2p)}")
        print()
        print(
            f"Average tests maintained per bug (P2P): {sum(all_p2p) / len(all_p2p):.2f}"
        )
        print(
            f"Median tests maintained per bug (P2P):  {sorted(all_p2p)[len(all_p2p) // 2]}"
        )

    print()
    print("=" * 80)


def save_report(analysis: Dict[str, Any], output_file: str) -> None:
    """Save the analysis report to a JSON file."""
    with open(output_file, "w") as f:
        json.dump(analysis, f, indent=2)
    print(f"Detailed report saved to: {output_file}")


def plot_bug_distribution(
    analysis: Dict[str, Any],
    output_path: str,
    show_generated_bugs: bool = False,
    show_timeout_bugs: bool = False,
) -> None:
    """Plot bar chart of bug distribution by modifier type.

    Args:
        analysis: Analysis results dictionary
        output_path: Path to save the plot
        show_generated_bugs: Whether to show generated bugs bar
        show_timeout_bugs: Whether to show timeout bugs bar stacked on validated
    """
    # Extract data
    generated_by_modifier = analysis.get("generated_by_modifier", {})
    validated_by_modifier = analysis.get("validated_by_modifier", {})
    timeout_by_modifier = analysis.get("timeout_by_modifier", {})

    # If it's aggregate data, handle differently
    if "aggregate_statistics" in analysis:
        modifier_data = analysis["aggregate_statistics"]["by_modifier"]
        generated_by_modifier = {k: v["generated"] for k, v in modifier_data.items()}
        validated_by_modifier = {
            k: {"total": v["validated"], "passed": v["passed"]}
            for k, v in modifier_data.items()
        }
        timeout_by_modifier = {k: v.get("timeout", 0) for k, v in modifier_data.items()}

    if not generated_by_modifier:
        print("No data to plot")
        return

    # Sort modifiers by generated count (descending)
    sorted_modifiers = sorted(
        generated_by_modifier.items(), key=lambda x: x[1], reverse=True
    )

    modifier_keys = [m[0] for m in sorted_modifiers]
    modifiers_display = [m[0].replace("func_pm_", "") for m in sorted_modifiers]
    generated_counts = [m[1] for m in sorted_modifiers]

    # Get validated, passed, and timeout counts for each modifier
    validated_counts = []
    passed_counts = []
    timeout_counts = []
    for modifier_key in modifier_keys:
        if modifier_key in validated_by_modifier:
            if isinstance(validated_by_modifier[modifier_key], dict):
                validated_counts.append(
                    validated_by_modifier[modifier_key].get("total", 0)
                )
                passed_counts.append(
                    validated_by_modifier[modifier_key].get("passed", 0)
                )
            else:
                validated_counts.append(validated_by_modifier[modifier_key])
                passed_counts.append(0)
        else:
            validated_counts.append(0)
            passed_counts.append(0)

        # Get timeout count for this modifier
        timeout_counts.append(timeout_by_modifier.get(modifier_key, 0))

    # Filter out modifiers with zero passed bugs
    filtered_data = [
        (mod, gen, val, pas, tim)
        for mod, gen, val, pas, tim in zip(
            modifiers_display,
            generated_counts,
            validated_counts,
            passed_counts,
            timeout_counts,
        )
        if pas > 0
    ]

    if not filtered_data:
        print("No modifiers with passed bugs to plot")
        return

    # Unpack filtered data
    (
        modifiers_display,
        generated_counts,
        validated_counts,
        passed_counts,
        timeout_counts,
    ) = zip(*filtered_data)

    # Create figure and axis
    fig, ax = plt.subplots(figsize=(14, 8.8))

    # Set positions for bars
    x = np.arange(len(modifiers_display))
    width = 0.6

    # Create overlaid bars (drawn from back to front)
    if show_generated_bugs:
        # Back: Generated (lightgray - 10% darker than whitesmoke)
        bars0 = ax.bar(
            x,
            generated_counts,
            width,
            label="Generated",
            color="lightgray",
            edgecolor="none",
            zorder=1,
        )
        # Middle: Validated (gray - 10% darker than silver)
        bars1 = ax.bar(
            x,
            validated_counts,
            width,
            label="Validated",
            color="gray",
            edgecolor="none",
            zorder=2,
        )
        # Front: Passed (black) - overlay on validated
        bars2 = ax.bar(
            x,
            passed_counts,
            width,
            label="Passed",
            color="black",
            edgecolor="none",
            zorder=3,
        )
        # Timeout bars stacked on top of validated (dotted pattern)
        if show_timeout_bugs:
            bars3 = ax.bar(
                x,
                timeout_counts,
                width,
                bottom=validated_counts,
                label="Timeout",
                color="gray",
                edgecolor="black",
                linewidth=0,
                hatch="...",
                zorder=4,
            )
    else:
        # Back: Validated (light grey)
        bars1 = ax.bar(
            x,
            validated_counts,
            width,
            label="Validated",
            color="lightgrey",
            edgecolor="none",
            zorder=1,
        )
        # Front: Passed (black) - overlay on validated
        bars2 = ax.bar(
            x,
            passed_counts,
            width,
            label="Passed",
            color="black",
            edgecolor="none",
            zorder=2,
        )
        # Timeout bars stacked on top of validated (dotted pattern)
        if show_timeout_bugs:
            bars3 = ax.bar(
                x,
                timeout_counts,
                width,
                bottom=validated_counts,
                label="Timeout",
                color="lightgrey",
                edgecolor="black",
                linewidth=0,
                hatch="...",
                zorder=3,
            )

    # Customize plot
    ax.set_xlabel("Modifier Type", fontsize=22, fontweight="bold")
    ax.set_ylabel("Number of Bugs", fontsize=22, fontweight="bold")
    ax.set_title(
        "Bug Distribution by Modifier Type", fontsize=24, fontweight="bold", pad=20
    )
    ax.set_xticks(x)
    ax.set_xticklabels(modifiers_display, rotation=45, ha="right", fontsize=20)
    ax.tick_params(axis="y", labelsize=20)
    ax.legend(fontsize=20, loc="upper right")
    ax.grid(axis="y", alpha=0.3, linestyle="--")

    # Add value labels on bars
    if show_generated_bugs:
        for i, (gen, val, pas, tim) in enumerate(
            zip(generated_counts, validated_counts, passed_counts, timeout_counts)
        ):
            # Label for generated (at the top of generated bar)
            ax.text(
                x[i],
                gen,
                f"{int(gen)}",
                ha="center",
                va="bottom",
                fontsize=16,
                fontweight="bold",
                color="dimgrey",
            )
            # Label for validated (at the top of validated bar)
            if not show_timeout_bugs:
                ax.text(
                    x[i],
                    val,
                    f"{int(val)}",
                    ha="center",
                    va="bottom",
                    fontsize=16,
                    fontweight="bold",
                    color="dimgrey",
                )
            # Label for passed (at the top of passed bar)
            ax.text(
                x[i],
                pas,
                f"{int(pas)}",
                ha="center",
                va="bottom",
                fontsize=16,
                fontweight="bold",
                color="white",
            )
            # Label for timeout (at the top of timeout bar)
            if show_timeout_bugs and tim > 0:
                ax.text(
                    x[i],
                    val + tim,
                    f"{int(gen)}",
                    ha="center",
                    va="bottom",
                    fontsize=16,
                    fontweight="bold",
                    color="dimgrey",
                )
    else:
        for i, (gen, val, pas, tim) in enumerate(
            zip(generated_counts, validated_counts, passed_counts, timeout_counts)
        ):
            # Label for validated (at the top of validated bar)
            if not show_timeout_bugs:
                ax.text(
                    x[i],
                    val,
                    f"{int(val)}",
                    ha="center",
                    va="bottom",
                    fontsize=16,
                    fontweight="bold",
                    color="dimgrey",
                )
            # Label for passed (at the top of passed bar)
            ax.text(
                x[i],
                pas,
                f"{int(pas)}",
                ha="center",
                va="bottom",
                fontsize=16,
                fontweight="bold",
                color="black",
            )
            # Label for timeout (at the top of timeout bar)
            if show_timeout_bugs and tim > 0:
                ax.text(
                    x[i],
                    val + tim,
                    f"{int(gen)}",
                    ha="center",
                    va="bottom",
                    fontsize=16,
                    fontweight="bold",
                    color="dimgrey",
                )

    # Tight layout to prevent label cutoff
    plt.tight_layout()

    # Ensure output directory exists
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)

    # Save plot
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    plt.close()

    print(f"Bug distribution plot saved to: {output_path}")


def plot_per_repo_distribution(
    all_analyses: list[Dict[str, Any]], output_path: str, show_repo_owner: bool = False
) -> None:
    """Plot per-repo breakdown of validated, passed, and timeout bugs.

    Args:
        all_analyses: List of analysis results for each repo
        output_path: Path to save the plot
        show_repo_owner: Whether to show repo owner in labels
    """
    if not all_analyses:
        print("No data to plot")
        return

    # Extract data per repo
    repos = [a["repo_id"] for a in all_analyses]
    validated = [a["total_validated"] for a in all_analyses]
    passed = [a["total_passed"] for a in all_analyses]
    timeout = [a.get("total_timeouts", 0) for a in all_analyses]

    # Truncate commit_id from repo names (remove part after last dot)
    repos_display = [r.rsplit(".", 1)[0] for r in repos]

    # Replace __ with / and optionally hide owner
    if show_repo_owner:
        repos_display = [r.replace("__", "/") for r in repos_display]
    else:
        # Hide owner (everything before and including __)
        repos_display = [
            r.split("__", 1)[-1] if "__" in r else r for r in repos_display
        ]

    # Create figure
    fig, ax = plt.subplots(figsize=(16, 10))

    x = np.arange(len(repos))
    width = 0.25

    # Create grouped bars
    ax.bar(x - width, validated, width, label="Validated", color="lightgrey")
    ax.bar(x, passed, width, label="Passed", color="black")
    ax.bar(x + width, timeout, width, label="Timeout", color="lightgrey", hatch="...")

    # Customize plot
    ax.set_xlabel("Repository", fontsize=22, fontweight="bold")
    ax.set_ylabel("Number of Bugs", fontsize=22, fontweight="bold")
    ax.set_title(
        "Per-Repository Bug Distribution", fontsize=24, fontweight="bold", pad=20
    )
    ax.set_xticks(x)
    ax.set_xticklabels(repos_display, rotation=45, ha="right", fontsize=14)
    ax.tick_params(axis="y", labelsize=20)
    ax.legend(fontsize=20, loc="upper right")
    ax.grid(axis="y", alpha=0.3, linestyle="--")

    plt.tight_layout()

    # Ensure output directory exists
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)

    # Save plot
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    plt.close()

    print(f"Per-repo distribution plot saved to: {output_path}")


def get_repo_info(owner: str, repo: str) -> dict:
    """Get repository info from GitHub API using curl.

    Args:
        owner: Repository owner
        repo: Repository name

    Returns:
        Dictionary with 'size' (in KB) and 'stars' (stargazers_count), or empty dict if request fails
    """
    url = f"https://api.github.com/repos/{owner}/{repo}"

    # Build curl command with authentication if GITHUB_TOKEN is available
    curl_cmd = ["curl", "-s"]

    # Check for GITHUB_TOKEN environment variable
    github_token = os.environ.get("GITHUB_TOKEN")
    if github_token:
        curl_cmd.extend(["-H", f"Authorization: Bearer {github_token}"])

    curl_cmd.extend(["-H", "Accept: application/vnd.github+json"])
    curl_cmd.append(url)

    try:
        result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=10)

        if result.returncode == 0 and result.stdout.strip():
            try:
                data = json.loads(result.stdout)

                # Check for GitHub API errors (rate limit, not found, etc.)
                if "message" in data:
                    if "rate limit" in data["message"].lower():
                        print(
                            f"Warning: GitHub API rate limit exceeded. Message: {data['message']}"
                        )
                    else:
                        print(
                            f"Warning: GitHub API error for {owner}/{repo}: {data['message']}"
                        )
                    return {}

                # Successfully got data
                return {
                    "size": data.get("size", 0),
                    "stars": data.get("stargazers_count", 0),
                }
            except json.JSONDecodeError as e:
                print(f"Warning: Failed to parse JSON response for {owner}/{repo}: {e}")
                return {}
        else:
            print(
                f"Warning: Failed to get repo info for {owner}/{repo} (curl returned {result.returncode})"
            )
            return {}
    except Exception as e:
        print(f"Warning: Error getting repo info for {owner}/{repo}: {e}")
        return {}


def plot_timeout_vs_tests_correlation(
    all_analyses: list[Dict[str, Any]], output_path: str
) -> None:
    """Plot correlation between percent of timeout bugs and total number of tests.

    Args:
        all_analyses: List of analysis results for each repo
        output_path: Path to save the plot
    """
    if not all_analyses:
        print("No data to plot")
        return

    # Extract data per repo
    test_counts = []
    timeout_percentages = []
    repo_names = []

    for analysis in all_analyses:
        test_count = analysis.get("test_count", 0)
        total_generated = analysis.get("total_generated", 0)
        total_timeouts = analysis.get("total_timeouts", 0)

        # Skip repos with no tests or no bugs
        if test_count == 0 or total_generated == 0:
            continue

        timeout_pct = (total_timeouts / total_generated) * 100
        test_counts.append(test_count)
        timeout_percentages.append(timeout_pct)

        # Truncate commit_id from repo name
        repo_name = analysis["repo_id"].rsplit(".", 1)[0]
        # Hide owner (everything before and including __)
        repo_name = repo_name.split("__", 1)[-1] if "__" in repo_name else repo_name
        repo_names.append(repo_name)

    if not test_counts:
        print("No data with valid test counts to plot")
        return

    # Convert to numpy arrays for easier manipulation
    test_counts = np.array(test_counts)
    timeout_percentages = np.array(timeout_percentages)
    repo_names = np.array(repo_names)

    # Identify outliers using IQR method on both axes
    q1_x, q3_x = np.percentile(test_counts, [25, 75])
    iqr_x = q3_x - q1_x
    lower_x, upper_x = q1_x - 1.5 * iqr_x, q3_x + 1.5 * iqr_x

    q1_y, q3_y = np.percentile(timeout_percentages, [25, 75])
    iqr_y = q3_y - q1_y
    lower_y, upper_y = q1_y - 1.5 * iqr_y, q3_y + 1.5 * iqr_y

    # Create mask for non-outliers
    mask_x = (test_counts >= lower_x) & (test_counts <= upper_x)
    mask_y = (timeout_percentages >= lower_y) & (timeout_percentages <= upper_y)
    mask = mask_x & mask_y

    test_counts_filtered = test_counts[mask]
    timeout_percentages_filtered = timeout_percentages[mask]
    outliers_x = test_counts[~mask]
    outliers_y = timeout_percentages[~mask]

    # Create figure
    fig, ax = plt.subplots(figsize=(12, 8))

    # Scatter plot for non-outliers only
    ax.scatter(
        test_counts_filtered,
        timeout_percentages_filtered,
        alpha=0.6,
        s=100,
        color="black",
        label="Data",
    )

    # Print outliers if any (but don't plot them)
    if len(outliers_x) > 0:
        print(f"\nExcluded {len(outliers_x)} outlier(s) from correlation analysis:")
        outlier_repos = repo_names[~mask]
        for i, (repo, tests, timeout_pct) in enumerate(
            zip(outlier_repos, outliers_x, outliers_y)
        ):
            print(f"  {i + 1}. {repo}: {int(tests)} tests, {timeout_pct:.1f}% timeout")
        print()

    # Add linear regression line using filtered data
    if len(test_counts_filtered) > 1:
        z = np.polyfit(test_counts_filtered, timeout_percentages_filtered, 1)
        p = np.poly1d(z)
        x_line = np.linspace(min(test_counts_filtered), max(test_counts_filtered), 100)
        ax.plot(
            x_line,
            p(x_line),
            "r--",
            alpha=0.8,
            linewidth=2,
            label=f"y={z[0]:.4f}x+{z[1]:.2f}",
        )

        # Calculate correlation coefficient on filtered data
        correlation = np.corrcoef(test_counts_filtered, timeout_percentages_filtered)[
            0, 1
        ]
        ax.text(
            0.05,
            0.95,
            f"Correlation: {correlation:.3f}",
            transform=ax.transAxes,
            fontsize=16,
            verticalalignment="top",
            bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.5),
        )

    # Customize plot
    ax.set_xlabel("Total Number of Unit Tests", fontsize=18, fontweight="bold")
    ax.set_ylabel("Timeout Bugs (%)", fontsize=18, fontweight="bold")
    ax.set_title(
        "Correlation: Timeout Bugs vs Number of Tests",
        fontsize=20,
        fontweight="bold",
        pad=20,
    )
    ax.tick_params(axis="both", labelsize=14)
    ax.grid(alpha=0.3, linestyle="--")
    ax.legend(fontsize=14, loc="upper right")

    plt.tight_layout()

    # Ensure output directory exists
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)

    # Save plot
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    plt.close()

    print(f"Timeout vs tests correlation plot saved to: {output_path}")


def plot_num_tests_repo_size_correlation(
    all_analyses: list[Dict[str, Any]], output_path: str
) -> None:
    """Plot correlation between number of tests and repository size.

    Args:
        all_analyses: List of analysis results for each repo
        output_path: Path to save the plot
    """
    if not all_analyses:
        print("No data to plot")
        return

    # Extract data per repo
    test_counts = []
    repo_sizes = []
    repo_names = []

    github_token = os.environ.get("GITHUB_TOKEN")
    if github_token:
        print("\nFetching repository sizes from GitHub API (authenticated)...")
    else:
        print(
            "\nFetching repository sizes from GitHub API (unauthenticated - rate limited to 60 requests/hour)..."
        )
        print(
            "Tip: Set GITHUB_TOKEN environment variable to increase rate limit to 5000 requests/hour"
        )

    for analysis in all_analyses:
        test_count = analysis.get("test_count", 0)
        repo_id = analysis["repo_id"]

        # Skip repos with no tests
        if test_count == 0:
            continue

        # Parse repo_id to extract owner and repo name
        # Format: owner__repo.commit_hash
        repo_full = repo_id.rsplit(".", 1)[0]  # Remove commit hash
        if "__" in repo_full:
            owner, repo = repo_full.split("__", 1)

            # Get repo info from GitHub API
            repo_info = get_repo_info(owner, repo)
            repo_size = repo_info.get("size", 0)

            if repo_size > 0:
                test_counts.append(test_count)
                repo_sizes.append(repo_size)
                repo_names.append(repo)

            # Small delay to avoid rate limiting
            time.sleep(0.1)

    if not test_counts:
        print("No data with valid test counts and repo sizes to plot")
        return

    print(f"Successfully fetched sizes for {len(test_counts)} repositories\n")

    # Convert to numpy arrays for easier manipulation
    test_counts = np.array(test_counts)
    repo_sizes = np.array(repo_sizes)
    repo_names = np.array(repo_names)

    # Identify outliers using IQR method on both axes
    q1_x, q3_x = np.percentile(repo_sizes, [25, 75])
    iqr_x = q3_x - q1_x
    lower_x, upper_x = q1_x - 1.5 * iqr_x, q3_x + 1.5 * iqr_x

    q1_y, q3_y = np.percentile(test_counts, [25, 75])
    iqr_y = q3_y - q1_y
    lower_y, upper_y = q1_y - 1.5 * iqr_y, q3_y + 1.5 * iqr_y

    # Create mask for non-outliers
    mask_x = (repo_sizes >= lower_x) & (repo_sizes <= upper_x)
    mask_y = (test_counts >= lower_y) & (test_counts <= upper_y)
    mask = mask_x & mask_y

    repo_sizes_filtered = repo_sizes[mask]
    test_counts_filtered = test_counts[mask]
    outliers_x = repo_sizes[~mask]
    outliers_y = test_counts[~mask]

    # Create figure
    fig, ax = plt.subplots(figsize=(12, 8))

    # Scatter plot for non-outliers only
    ax.scatter(
        repo_sizes_filtered,
        test_counts_filtered,
        alpha=0.6,
        s=100,
        color="black",
        label="Data",
    )

    # Print outliers if any (but don't plot them)
    if len(outliers_x) > 0:
        print(f"Excluded {len(outliers_x)} outlier(s) from correlation analysis:")
        outlier_repos = repo_names[~mask]
        for i, (repo, size, tests) in enumerate(
            zip(outlier_repos, outliers_x, outliers_y)
        ):
            print(f"  {i + 1}. {repo}: {int(size)} KB, {int(tests)} tests")
        print()

    # Add linear regression line using filtered data
    if len(repo_sizes_filtered) > 1:
        z = np.polyfit(repo_sizes_filtered, test_counts_filtered, 1)
        p = np.poly1d(z)
        x_line = np.linspace(min(repo_sizes_filtered), max(repo_sizes_filtered), 100)
        ax.plot(
            x_line,
            p(x_line),
            "r--",
            alpha=0.8,
            linewidth=2,
            label=f"y={z[0]:.4f}x+{z[1]:.2f}",
        )

        # Calculate correlation coefficient on filtered data
        correlation = np.corrcoef(repo_sizes_filtered, test_counts_filtered)[0, 1]
        ax.text(
            0.05,
            0.95,
            f"Correlation: {correlation:.3f}",
            transform=ax.transAxes,
            fontsize=16,
            verticalalignment="top",
            bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.5),
        )

    # Customize plot
    ax.set_xlabel("Repository Size (KB)", fontsize=18, fontweight="bold")
    ax.set_ylabel("Total Number of Unit Tests", fontsize=18, fontweight="bold")
    ax.set_title(
        "Correlation: Number of Tests vs Repository Size",
        fontsize=20,
        fontweight="bold",
        pad=20,
    )
    ax.tick_params(axis="both", labelsize=14)
    ax.grid(alpha=0.3, linestyle="--")
    ax.legend(fontsize=14, loc="upper right")

    plt.tight_layout()

    # Ensure output directory exists
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)

    # Save plot
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    plt.close()

    print(f"Number of tests vs repo size correlation plot saved to: {output_path}")


def plot_num_tests_repo_star_correlation(
    all_analyses: list[Dict[str, Any]], output_path: str
) -> None:
    """Plot correlation between number of tests and repository stars.

    Args:
        all_analyses: List of analysis results for each repo
        output_path: Path to save the plot
    """
    if not all_analyses:
        print("No data to plot")
        return

    # Extract data per repo
    test_counts = []
    repo_stars = []
    repo_names = []

    github_token = os.environ.get("GITHUB_TOKEN")
    if github_token:
        print("\nFetching repository stars from GitHub API (authenticated)...")
    else:
        print(
            "\nFetching repository stars from GitHub API (unauthenticated - rate limited to 60 requests/hour)..."
        )
        print(
            "Tip: Set GITHUB_TOKEN environment variable to increase rate limit to 5000 requests/hour"
        )

    for analysis in all_analyses:
        test_count = analysis.get("test_count", 0)
        repo_id = analysis["repo_id"]

        # Skip repos with no tests
        if test_count == 0:
            continue

        # Parse repo_id to extract owner and repo name
        # Format: owner__repo.commit_hash
        repo_full = repo_id.rsplit(".", 1)[0]  # Remove commit hash
        if "__" in repo_full:
            owner, repo = repo_full.split("__", 1)

            # Get repo info from GitHub API
            repo_info = get_repo_info(owner, repo)
            stars = repo_info.get("stars", 0)

            if stars > 0:
                test_counts.append(test_count)
                repo_stars.append(stars)
                repo_names.append(repo)

            # Small delay to avoid rate limiting
            time.sleep(0.1)

    if not test_counts:
        print("No data with valid test counts and repo stars to plot")
        return

    print(f"Successfully fetched stars for {len(test_counts)} repositories\n")

    # Convert to numpy arrays for easier manipulation
    test_counts = np.array(test_counts)
    repo_stars = np.array(repo_stars)
    repo_names = np.array(repo_names)

    # Identify outliers using IQR method on both axes
    q1_x, q3_x = np.percentile(repo_stars, [25, 75])
    iqr_x = q3_x - q1_x
    lower_x, upper_x = q1_x - 1.5 * iqr_x, q3_x + 1.5 * iqr_x

    q1_y, q3_y = np.percentile(test_counts, [25, 75])
    iqr_y = q3_y - q1_y
    lower_y, upper_y = q1_y - 1.5 * iqr_y, q3_y + 1.5 * iqr_y

    # Create mask for non-outliers
    mask_x = (repo_stars >= lower_x) & (repo_stars <= upper_x)
    mask_y = (test_counts >= lower_y) & (test_counts <= upper_y)
    mask = mask_x & mask_y

    repo_stars_filtered = repo_stars[mask]
    test_counts_filtered = test_counts[mask]
    outliers_x = repo_stars[~mask]
    outliers_y = test_counts[~mask]

    # Create figure
    fig, ax = plt.subplots(figsize=(12, 8))

    # Scatter plot for non-outliers only
    ax.scatter(
        repo_stars_filtered,
        test_counts_filtered,
        alpha=0.6,
        s=100,
        color="black",
        label="Data",
    )

    # Print outliers if any (but don't plot them)
    if len(outliers_x) > 0:
        print(f"Excluded {len(outliers_x)} outlier(s) from correlation analysis:")
        outlier_repos = repo_names[~mask]
        for i, (repo, stars, tests) in enumerate(
            zip(outlier_repos, outliers_x, outliers_y)
        ):
            print(f"  {i + 1}. {repo}: {int(stars)} stars, {int(tests)} tests")
        print()

    # Add linear regression line using filtered data
    if len(repo_stars_filtered) > 1:
        z = np.polyfit(repo_stars_filtered, test_counts_filtered, 1)
        p = np.poly1d(z)
        x_line = np.linspace(min(repo_stars_filtered), max(repo_stars_filtered), 100)
        ax.plot(
            x_line,
            p(x_line),
            "r--",
            alpha=0.8,
            linewidth=2,
            label=f"y={z[0]:.4f}x+{z[1]:.2f}",
        )

        # Calculate correlation coefficient on filtered data
        correlation = np.corrcoef(repo_stars_filtered, test_counts_filtered)[0, 1]
        ax.text(
            0.05,
            0.95,
            f"Correlation: {correlation:.3f}",
            transform=ax.transAxes,
            fontsize=16,
            verticalalignment="top",
            bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.5),
        )

    # Customize plot
    ax.set_xlabel("Repository Stars", fontsize=18, fontweight="bold")
    ax.set_ylabel("Total Number of Unit Tests", fontsize=18, fontweight="bold")
    ax.set_title(
        "Correlation: Number of Tests vs Repository Stars",
        fontsize=20,
        fontweight="bold",
        pad=20,
    )
    ax.tick_params(axis="both", labelsize=14)
    ax.grid(alpha=0.3, linestyle="--")
    ax.legend(fontsize=14, loc="upper right")

    plt.tight_layout()

    # Ensure output directory exists
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)

    # Save plot
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    plt.close()

    print(f"Number of tests vs repo stars correlation plot saved to: {output_path}")


def discover_repos() -> list[str]:
    """Discover all repos under logs/run_validation.

    Returns:
        List of repo IDs found in the validation directory
    """
    validation_base = Path("logs/run_validation")
    if not validation_base.exists():
        return []

    repos = []
    for item in validation_base.iterdir():
        if item.is_dir():
            repos.append(item.name)

    return sorted(repos)


def print_aggregate_statistics(all_analyses: list[Dict[str, Any]]) -> None:
    """Print aggregate statistics across all repos."""

    total_repos = len(all_analyses)
    total_generated = sum(a["total_generated"] for a in all_analyses)
    total_validated = sum(a["total_validated"] for a in all_analyses)
    total_passed = sum(a["total_passed"] for a in all_analyses)
    total_failed = sum(a["total_failed"] for a in all_analyses)
    total_timeouts = sum(a.get("total_timeouts", 0) for a in all_analyses)

    # Aggregate by modifier across all repos
    modifier_stats = defaultdict(
        lambda: {
            "generated": 0,
            "validated": 0,
            "passed": 0,
            "failed": 0,
            "timeout": 0,
            "f2p_counts": [],
            "p2p_counts": [],
        }
    )

    for analysis in all_analyses:
        for modifier, count in analysis["generated_by_modifier"].items():
            modifier_stats[modifier]["generated"] += count

        for modifier, data in analysis["validated_by_modifier"].items():
            modifier_stats[modifier]["validated"] += data["total"]
            modifier_stats[modifier]["passed"] += data["passed"]
            modifier_stats[modifier]["failed"] += data["failed"]
            modifier_stats[modifier]["f2p_counts"].extend(data["f2p_counts"])
            modifier_stats[modifier]["p2p_counts"].extend(data["p2p_counts"])

        for modifier, count in analysis.get("timeout_by_modifier", {}).items():
            modifier_stats[modifier]["timeout"] += count

    print("\n")
    print("=" * 80)
    print("AGGREGATE STATISTICS ACROSS ALL REPOS")
    print("=" * 80)
    print()

    print("OVERALL STATISTICS")
    print("-" * 80)
    print(f"Total repositories analyzed:    {total_repos}")
    print(f"Total bugs generated:           {total_generated}")
    print(f"Total bugs validated:           {total_validated}")
    if total_validated > 0:
        print(
            f"Bugs that passed validation:    {total_passed} ({total_passed / total_validated * 100:.1f}%)"
        )
        print(
            f"Bugs that failed validation:    {total_failed} ({total_failed / total_validated * 100:.1f}%)"
        )
    print()

    print("PER-MODIFIER STATISTICS (AGGREGATED)")
    print("-" * 80)
    print(
        f"{'Modifier':<35} {'Generated':<12} {'Validated':<12} {'Passed':<12} {'Pass Rate':<12}"
    )
    print("-" * 80)

    sorted_modifiers = sorted(
        modifier_stats.items(), key=lambda x: x[1]["generated"], reverse=True
    )

    for modifier, stats in sorted_modifiers:
        validated_count = stats["validated"]
        passed_count = stats["passed"]
        pass_rate = (passed_count / max(validated_count, 1)) * 100

        print(
            f"{modifier:<35} {stats['generated']:<12} {validated_count:<12} {passed_count:<12} {pass_rate:>10.1f}%"
        )

    print()

    print("TEST FAILURE STATISTICS (AGGREGATED)")
    print("-" * 80)
    print(
        f"{'Modifier':<35} {'Avg F2P':<12} {'Min F2P':<12} {'Max F2P':<12} {'Avg P2P':<12}"
    )
    print("-" * 80)

    for modifier, stats in sorted_modifiers:
        f2p_counts = stats["f2p_counts"]
        p2p_counts = stats["p2p_counts"]

        if f2p_counts:
            avg_f2p = sum(f2p_counts) / len(f2p_counts)
            min_f2p = min(f2p_counts)
            max_f2p = max(f2p_counts)
            avg_p2p = sum(p2p_counts) / len(p2p_counts)

            print(
                f"{modifier:<35} {avg_f2p:<12.2f} {min_f2p:<12} {max_f2p:<12} {avg_p2p:<12.2f}"
            )

    print()
    print("=" * 80)


def main():
    parser = argparse.ArgumentParser(
        description="Analyze procedurally generated bugs and validation results"
    )
    parser.add_argument(
        "--repo",
        "-r",
        type=str,
        default=None,
        help="Repository identifier (e.g., Instagram__MonkeyType.70c3acf6). If not provided, analyzes all repos.",
    )
    parser.add_argument(
        "--output",
        "-o",
        type=str,
        default=None,
        help="Output file for detailed JSON report (default: logs/analysis/<repo_id>_analysis.json or logs/analysis/aggregate_analysis.json)",
    )
    parser.add_argument(
        "--show-generated-bugs",
        action="store_true",
        default=False,
        help="Show generated bugs as another bar behind validated and passed. If enabled, validated bar shows in grey and generated in light grey.",
    )
    parser.add_argument(
        "--show-timeout-bugs",
        action="store_true",
        default=False,
        help="Show timeout bugs as a dotted bar stacked on top of validated bugs.",
    )
    parser.add_argument(
        "--show-repo-owner",
        action="store_true",
        default=False,
        help="Show repository owner in per-repo plot labels.",
    )

    args = parser.parse_args()

    if args.repo:
        # Analyze single repo
        analysis = analyze_bugs(args.repo)
        print_statistics(analysis)

        if args.output is None:
            output_dir = Path("logs/analysis")
            output_dir.mkdir(parents=True, exist_ok=True)
            args.output = str(output_dir / f"{args.repo}_analysis.json")

        save_report(analysis, args.output)

        # Plot bug distribution
        plot_output = Path("logs/analysis") / "bug_distribution.png"
        plot_bug_distribution(
            analysis, str(plot_output), args.show_generated_bugs, args.show_timeout_bugs
        )
    else:
        # Analyze all repos
        repos = discover_repos()

        if not repos:
            print("No repositories found in logs/run_validation/")
            return

        print(f"Found {len(repos)} repositories to analyze")
        print()

        all_analyses = []

        for repo in repos:
            try:
                analysis = analyze_bugs(repo)
                all_analyses.append(analysis)
                print_statistics(analysis)
                print()
            except FileNotFoundError as e:
                print(f"Skipping {repo}: {e}")
                print()

        if all_analyses:
            print_aggregate_statistics(all_analyses)

            # Save aggregate report
            if args.output is None:
                output_dir = Path("logs/analysis")
                output_dir.mkdir(parents=True, exist_ok=True)
                args.output = str(output_dir / "aggregate_analysis.json")

            # Calculate aggregate statistics for JSON
            total_generated = sum(a["total_generated"] for a in all_analyses)
            total_validated = sum(a["total_validated"] for a in all_analyses)
            total_passed = sum(a["total_passed"] for a in all_analyses)
            total_failed = sum(a["total_failed"] for a in all_analyses)
            total_timeouts = sum(a.get("total_timeouts", 0) for a in all_analyses)

            modifier_stats = defaultdict(
                lambda: {
                    "generated": 0,
                    "validated": 0,
                    "passed": 0,
                    "failed": 0,
                    "timeout": 0,
                    "f2p_counts": [],
                    "p2p_counts": [],
                }
            )

            for analysis in all_analyses:
                for modifier, count in analysis["generated_by_modifier"].items():
                    modifier_stats[modifier]["generated"] += count

                for modifier, data in analysis["validated_by_modifier"].items():
                    modifier_stats[modifier]["validated"] += data["total"]
                    modifier_stats[modifier]["passed"] += data["passed"]
                    modifier_stats[modifier]["failed"] += data["failed"]
                    modifier_stats[modifier]["f2p_counts"].extend(data["f2p_counts"])
                    modifier_stats[modifier]["p2p_counts"].extend(data["p2p_counts"])

                for modifier, count in analysis.get("timeout_by_modifier", {}).items():
                    modifier_stats[modifier]["timeout"] += count

            # Calculate summary statistics for each modifier
            modifier_summaries = {}
            for modifier, stats in modifier_stats.items():
                summary = {
                    "generated": stats["generated"],
                    "validated": stats["validated"],
                    "passed": stats["passed"],
                    "failed": stats["failed"],
                    "timeout": stats["timeout"],
                    "pass_rate": (stats["passed"] / max(stats["validated"], 1)) * 100,
                }

                if stats["f2p_counts"]:
                    summary["f2p_avg"] = sum(stats["f2p_counts"]) / len(
                        stats["f2p_counts"]
                    )
                    summary["f2p_min"] = min(stats["f2p_counts"])
                    summary["f2p_max"] = max(stats["f2p_counts"])
                    summary["p2p_avg"] = sum(stats["p2p_counts"]) / len(
                        stats["p2p_counts"]
                    )

                modifier_summaries[modifier] = summary

            aggregate_data = {
                "total_repos": len(all_analyses),
                "repos": [a["repo_id"] for a in all_analyses],
                "aggregate_statistics": {
                    "total_generated": total_generated,
                    "total_validated": total_validated,
                    "total_passed": total_passed,
                    "total_failed": total_failed,
                    "total_timeouts": total_timeouts,
                    "pass_rate": (total_passed / max(total_validated, 1)) * 100,
                    "by_modifier": modifier_summaries,
                },
                "individual_analyses": all_analyses,
            }
            save_report(aggregate_data, args.output)

            # Plot aggregate bug distribution
            plot_output = Path("logs/analysis") / "bug_distribution.png"
            plot_bug_distribution(
                aggregate_data,
                str(plot_output),
                args.show_generated_bugs,
                args.show_timeout_bugs,
            )

            # Plot per-repo distribution
            per_repo_output = Path("logs/analysis") / "per_repo_bug_distribution.png"
            plot_per_repo_distribution(
                all_analyses, str(per_repo_output), args.show_repo_owner
            )

            # Plot timeout vs tests correlation
            correlation_output = (
                Path("logs/analysis") / "num_tests_timeout_correlation.png"
            )
            plot_timeout_vs_tests_correlation(all_analyses, str(correlation_output))

            # Plot num_tests vs repo_size correlation
            repo_size_output = (
                Path("logs/analysis") / "num_tests_repo_size_correlation.png"
            )
            plot_num_tests_repo_size_correlation(all_analyses, str(repo_size_output))

            # Plot num_tests vs repo_stars correlation
            repo_star_output = (
                Path("logs/analysis") / "num_tests_repo_star_correlation.png"
            )
            plot_num_tests_repo_star_correlation(all_analyses, str(repo_star_output))


if __name__ == "__main__":
    main()
